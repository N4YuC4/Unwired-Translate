# --- Proje ve Model Ayarları ---
proje_adi: "Translation"
model_mimarisi: "mt5-small"
model_teknigi: "16bit-LoRA"
versiyon: "V1"
model_adi: "google/mt5-small"

# --- Dil Ayarları ---
language:
  source: "English"
  target: "Turkish"

# --- Veri Ayarları ---
dataset:
  names: ["LAINCHAN","HPLT"]
  base_path: "datasets"
  start_line: 0
  max_lines: 230000
  read_first_set_completely: False
  test_size: 0.2
  random_state: 42
  cleaning:
    enabled: True
    similarity_threshold: 0.7
    gpu: True
    chunk_size: 10000

# --- Eğitim Hiperparametreleri ---
training:
  epochs: 4
  train_batch_size: 15
  lr: 0.0005
  gradient_accumulation_steps: 4
  percentile: 96
  max_len: 128
  use_dynamic_max_len: True

# --- QLoRA Hiperparametreleri ---
qlora:
  lora_rank: 64
  lora_alpha: 128
  lora_dropout: 0.05
  target_modules: "all-linear"

# --- Sistem Ayarları ---
system:
  gpu: True
  output_dir: "models"
  lora:
    base_dir: "{model_mimarisi}_{model_teknigi}_{proje_adi}_{veri_seti}_{versiyon}"
    lang_dir: "{source_lang}-{target_lang}"

artifacts:
  processed_data_dir: "artifacts/processed_data"
  results_dir: "artifacts/training_results"